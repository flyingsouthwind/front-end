## 模块学习

### Buffer

Buffer 是 Node.js 中为 Object 添加一种子类型，用于处理二进制数据。

Buffer 对象类型被创建的原因：因为 Node.js 用于服务端，存在众多操作文件的场景。如果使用传统的字符串，则需要将二进制的文件数据转换成字符串，操作完成后再从字符串转回二进制，转换会导致性能低下，无法满足具体的使用要求。所以，需要一种直接操作二进制数据的方式。

Buffer 对象与 ES 标准对象类型不同的是：它是一个"外挂"对象类型，通过 Buffer 模块实现，在 Node.js 程序启动时，自动加载模块并将 Buffer 对象挂载在全局上下文 global 上。

#### 内存分配

Buffer 对象的内存分配不是在 v8 的堆内存中，而是在 Node.js 的 C++ 层面实现内存的申请的。因为处理大量字节数据时，内存采用需要一点就向系统申请一点的方式，可能造成大量内存申请的系统调用，对操作系统有一定压力。因此，针对 Buffer 对象内存，Node.js 采用在 C++ 层面申请内存，在 js 中分配内存的策略。

需要特别注意的是，也正是因为 Buffer 对象是 JS 层面的，在 js 中分配内存，所以这些内存是能够被 V8 的垃圾回收机制标记回收的。

为了高效地使用申请来的内存，Node.js 采用了 slab 分配机制。该机制以 4KB 为界，将 Buffer 对象分为小对象和大对象：

- 小对象，≤ 4KB，Node.js 会预分配 4KB 内存，称为 slab 单元，然后小对象顺次相连写入该 slab 单元，若剩余内存不足以写入整个小对象时，则将相应的小对象写入下一个申请的 slab 单元中。只有同一个 slab 单元中的所有小对象在作用域释放并都可以回收时，整个 slab 单元才可被垃圾回收机制释放
- 大对象，＞4KB，Node.js 会预直接分配相应尺寸的内存用于写入大对象

slab 分配机制的优点：

- 放置过多小对象造成大量内存申请的系统调用
- 避免垃圾回收机制因创建太多独立的 Buffer 而过度使用

slab 分配机制的缺点：

- 对于存放小对象的 slab 单元，无法完全写满，造成内存浪费

#### 性能优化

Buffer 相关的性能优化，主要体现在两个方面：

1. Node.js 服务端直接返回二进制 Buffer 数据性能要比返回字符串高得多，例如：

   ```
   let http = require('http');
   let helloworld = "";
   
   for (let i = 0; i < 1024 * 10; i++) {
       helloworld += "a";
   }
   
   // helloworld = Buffer.from(helloworld);
   
   http.createServer(function (req, res) {
       res.writeHead(200);
       res.end(helloworld);
   }).listen(8001);
   ```

   当使用 Linux 的 ab 命令进行性能测试时，使用 Buffer 对象类型 helloworld 的传输效率要比使用字符串的效率高一倍。所以，在有文件读取时，直接使用二进制，或者将字符串转换成二进制数据以后再发送至前端，会有更好的性能

2. 在通过 fs.createReadStream() 进行文件读取时，当文件内容较多导致 Buffer 对象较大时，highWaterMark 参数设置的越大，系统调用次数越少，性能越高

#### 对象创建

Buffer 对象是一种类数组，其元素为 16 进制的两位数，即数值范围为 0 到 255

Buffer 对象的创建可以通过 Buffer 的静态方法实现：

* Buffer.alloc(size[, fill[, encoding]])，创建会初始化（即不设置 fill 时元素会默认初始化为 0）的 Buffer

  * size，必需，integer，Buffer 所需长度，单位字节
  * fill，可选，String | Buffer | integer， 用于预填充新 Buffer 的值，默认值为 0
  * encoding，可选，String，如果 fill 是一个字符串，则这是它的字符编码，默认值为 'utf8'

  ```
  const buf = Buffer.alloc(5);
  console.log(buf);
  
  // <Buffer 00 00 00 00 00>
  ```

  ```
  const buf = Buffer.alloc(5, 'a');
  console.log(buf);
  
  // <Buffer 61 61 61 61 61>
  ```

* Buffer.allocUnsafe(size)，创建未初始化的 Buffer，当分配空间＜ 4KB 时，会直接从之前预分配的 Buffer 里切割空间，因此速度比 allocUnsafeSlow 要快，当≥ 4KB 时二者速度无差异

  * size，必需，integer，Buffer 所需长度，单位字节

  ```
  const buf = Buffer.allocUnsafe(10);
  console.log(buf);
  // <Buffer a0 8b 28 3f 01 00 00 00 50 32>
  // (因为未初始化，输出的内容是内存原有数据，每次都不同)
  
  buf.fill(0);
  console.log(buf);
  // <Buffer 00 00 00 00 00 00 00 00 00 00>
  ```

* Buffer.allocUnsafeSlow(size)，创建未初始化的 Buffer

  * size，必需，integer，Buffer 所需长度，单位字节

* Buffer.from()，支持多种参数组合

  * Buffer.from(array)，使用八位字节数组 array 分配一个新的 Buffer

    * array，整型数组

    ```
    // 创建一个包含字符串 'buffer' 的 UTF-8 字节的新 Buffer。
    const buf = Buffer.from([0x62, 0x75, 0x66, 0x66, 0x65, 0x72]);
    ```

  * Buffer.from(arrayBuffer[, byteOffset[, length]])，创建 ArrayBuffer 的视图，但不会拷贝底层内存。 例如，当传入 TypedArray 的 .buffer 属性的引用时，新建的 Buffer 会与 TypedArray 共享同一内存

    * arrayBuffer ArrayBuffer 或 SharedArrayBuffer 或 TypedArray 的 .buffer 属性
    * byteOffset，开始拷贝的索引，默认值为 0
    * length，拷贝的字节数。默认值为 arrayBuffer.length - byteOffset

    ```
    const arr = new Uint16Array(2);
    
    arr[0] = 5000;
    arr[1] = 4000;
    
    // 与 `arr` 共享内存。
    const buf = Buffer.from(arr.buffer);
    
    console.log(buf);
    // 打印: <Buffer 88 13 a0 0f>
    
    // 改变原先的 Uint16Array 也会改变 Buffer。
    arr[1] = 6000;
    
    console.log(buf);
    // 打印: <Buffer 88 13 70 17>
    ```

  * Buffer.from(buffer)，拷贝 buffer 的数据到新建的 Buffer

    * buffer，要拷贝数据的 Buffer 或 Uint8Array

    ```
    const buf1 = Buffer.from('buffer');
    const buf2 = Buffer.from(buf1);
    
    buf1[0] = 0x61;
    
    console.log(buf1.toString());
    // 打印: auffer
    console.log(buf2.toString());
    // 打印: buffer
    ```

  * Buffer.from(string[, encoding])，创建一个包含 string 的新 Buffer

    * string，要编码的字符串
    * encoding，字符编码，默认值为 'utf8'

    ```
    const buf1 = Buffer.from('this is a tést');
    const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex');
    
    console.log(buf1.toString());
    // 打印: this is a tést
    console.log(buf2.toString());
    // 打印: this is a tést
    console.log(buf1.toString('ascii'));
    // 打印: this is a tC)st
    ```

#### 元素操作

由于 Buffer 对象是一种类数组，所有，可以像操作数据元素那样操作 Buffer 对象元素

```
let buf = Buffer.alloc(100);
console.log(buf.length);    // 100
console.log(typeof buf);    // object

buf[20] = -100;
console.log(buf[20]);       // 156

buf[21] = 300;
console.log(buf[21]);       // 44

buf[22] = 3.1415;
console.log(buf[22]);       // 3
```

需要注意的是：

* Buffer 对象元素是十六进制的，值在 0~255 之间
  * 如果值小于 0，则对数值进行连续累加 256 操作，直至值位于 0~255 之间
  * 如果值大于 255，则对数值进行连续累减 256 操作，直至值位于 0~255 之间
  * 如果值为小数，则直接省略小数部分

#### 类型转换

Buffer 对象可以与字符串之间相互转换。目前支持的字符串编码类型有：ASCII、UTF-8、UTF-16LE/UCS-2、Base64、Binary、Hex

可以通过下面的方法判断 Buffer 对象是否支持转换成相应编码的字符串：

* Buffer.isEncoding(encoding)，如果 encoding 是支持的字符编码，返回 true，否则返回 false
  * encoding，要检查的字符编码名称

对于不支持的编码类型，可以使用 iconv 或者 iconv-lite npm 包。

字符串转 Buffer：

* Buffer.from(string[, encoding])
* buf.write(string\[, offset\[, length]][, encoding])，根据 encoding 指定的字符编码将 string 写入到 buf 中的 offset 位置； 如果 buf 没有足够的空间保存整个字符串，则只会写入 string 的一部分；返回值为已写入的字节数
  * string，要写入 buf 的字符串
  * offset，开始写入位置的偏移量，默认为 0
  * length，要写入的字节数，默认值为 buf.length - offset
  * encoding，的字符编码，默认值为 'utf8'

Buffer 转字符串：

* buf.toString([encoding[, start[, end]]])，根据 encoding 指定的字符编码将 buf 解码成字符串中英对照提交修改
  * encoding，使用的字符编码，默认值为 'utf8'
  * start，开始解码的字节偏移量，默认值为 0
  * end，结束解码的字节偏移量（不包含），默认值为 buf.length

#### 合并拼接

Buffer 对象在进行 + 操作时，会按照 JS 的隐形类型转换习惯，通过 toString() 方法转换为字符串后进行加操作。

```
let buf1 = Buffer.from('a');
let buf2 = Buffer.from('b');

// 等同于let buf3 = buf1.toString() + buf2.toString();
let buf3 = buf1 + buf2;

console.log(buf3);					// ab
console.log(typeof buf3);		// string
```

需要注意的是，在 Buffer 对象的拼接中，容易出现**大对象中多字节字符分割后再拼接乱码**的问题。例如：

index.md 的内容：

```
床前明月光，疑是地上霜，举头望明月，低头是故乡。
```

创建阅读流：

```
let fs = require('fs');
let rs = fs.createReadStream('index.md', {
    highWaterMark: 11   // 流中数据段大小限定为11字节
});
let data = '';

rs.on("data", function (chunk) {
    console.log(chunk); // 这里的chunk为Buffer类型[object Uint8Array]
    data += chunk;      // 等同于 data += chunk.toString;
});

rs.on("end", function () {
    console.log(data);
});
```

控制台输出：

```
<Buffer e5 ba 8a e5 89 8d e6 98 8e e6 9c>
<Buffer 88 e5 85 89 ef bc 8c e7 96 91 e4>
<Buffer bc bc e5 9c b0 e4 b8 8a e9 9c 9c>
<Buffer ef bc 8c e4 b8 be e5 a4 b4 e6 9c>
<Buffer 9b e6 98 8e e6 9c 88 ef bc 8c e4>
<Buffer bd 8e e5 a4 b4 e6 98 af e6 95 85>
<Buffer e4 b9 a1 e3 80 82>
床前明��光，疑���地上霜，举头��明月，���头是故乡。
```

乱码产生的原因是：UTF-8 编码时每个汉字占 3 个字节，当一个汉字编码的 3 个字节被分割到两个 Buffer 流块中后，拼接时分别 toString() 导致。例如这里的阅读流按 11 个字节，即 3 个汉字 * 3 个字节 + 2 个字节 的方式分割时，前一个块的最后 2 个字节和后一个块的第 1 个字节 toString() 时无法有效解码

乱码解决的方案：

* fs.createReadStream() 中设置编码

  ```
  let fs = require('fs');
  let rs = fs.createReadStream('index.md', {
      encoding: 'utf8',   // 设置utf8编码
      highWaterMark: 11   // 流中数据段大小限定为11字节
  });
  let data = '';
  
  rs.on("data", function (chunk) {
      console.log(chunk); // 这里的chunk为String类型
      data += chunk;
  });
  
  rs.on("end", function () {
      console.log(data);
  });
  ```

  控制台输出：

  ```
  床前明
  月光，疑
  似地上霜
  ，举头
  望明月，
  低头是故
  乡。
  床前明月光，疑似地上霜，举头望明月，低头是故乡。
  ```

  乱码解决的原因：如果设置了编码，阅读流中传递就是String类型了，可读流对象内置的 decoder 对象会在二进制文件内容读取后传递前进行 Buffer -> String 的解码，而该对象能正确识别 3 字节的汉字编码，当设置数据段大小限制导致最后的个别字节无法完整解码时，该对象会将这些字节放在下一数据段中以求正确解码。例如，这里的第一个数据段只有 9 个字节，剩下的 2 个字节别放到了第 2 个数据段中

  需要注意的是，这个方案的限制是：decoder 对象目前只能处理 UTF-8、Base64和 UCS-2/UTF-16LE 3 种编码  				 			 		

* 等到 Buffer 数据段完全接收以后再进行拼接

  ```
  let fs = require('fs');
  
  let rs = fs.createReadStream('index.md', {
      highWaterMark: 11   // 流中数据段大小限定为11字节
  });
  let size = 0;
  let chunks = [];
  
  rs.on("data", function (chunk) {
      chunks.push(chunk);	// 这里的chunk为Buffer类型[object Uint8Array]
      size += chunk.length;
  });
  
  rs.on("end", function () {
      let buf = Buffer.concat(chunks, size);
      console.log(buf.toString('utf8'));
  });
  ```

  当然，如果需要 toString() 方法不支持的编码，可以使用 iconv 或者 iconv-lite npm 包进行转码。

#### ArrayBuffer

ArrayBuffer对象、TypedArray视图和DataView视图是 ES 标准操作二进制数据的接口，其中：

* ArrayBuffer 对象：代表内存中的一段二进制数据，可以通过“视图”进行操作
* TypedArray 视图：用来读写简单类型的二进制数据，共包括 9 种类型的视图，比如Uint8Array（无符号 8 位整数）数组视图、Int16Array（16 位整数）数组视图、Float32Array（32 位浮点数）数组视图等
* DataView 视图：用来读写复杂类型的二进制数据，比如第一个字节是 Uint8（无符号 8 位整数）、第二、三个字节是 Int16（16 位整数）、第四个字节开始是 Float32（32 位浮点数）等，此外还可以自定义字节序

ArrayBuffer 与 Buffer 的区别：

* Buffer 是 Node.js 中二进制处理的非官方 API，早于 ES 官方的 ArrayBuffer API
* Buffer 对象不像 ArrayBuffer 还分为对象和视图，需要二者配合完成二进制数据操作。Buffer 对象相当于 ArrayBuffer 对象 + Uint8Array TypedArray视图

#### 进一步学习

* https://www.jianshu.com/p/6a0bb73f2d64
* https://semlinker.com/node-buffer/#%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86
* http://taobaofed.org/blog/2017/08/31/nodejs-stream/

### Stream

Stream 并不是一种数据类型，而是一种数据封装及处理形式。

#### 源起

Stream 源起于大容量数据的处理，一次性处理较大容量的数据不仅对程序本身，对内存也同样是一个考验。

例如，使用 Node.js 读取一个 400M 的 txt 文件

```
var fs = require('fs')
fs.readFile('example/ua.txt', function (err, body) {
    console.log(body)
    console.log(body.toString())
})
```

程序输出：

```
⌘ node example/readFile.js
<Buffer 64 74 09 75 61 09 63 6f 75 6e 74 0a 0a 64 74 09 75 61 09 63 6f 75 6e 74 0a 32 30 31 35 31 32 30 38 09 4d 6f 7a 69 6c 6c 61 2f 35 2e 30 20 28 63 6f 6d ... >
buffer.js:382
    throw new Error('toString failed');
    ^

Error: toString failed
    at Buffer.toString (buffer.js:382:11)
    at /Users/zoubin/usr/src/zoub.in/stream-handbook/example/readFile.js:4:20
    at FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:380:3)
```

因为 Node.js 无法一次性读取大容量的数据并正确处理，尝试一次性处理大容量数据，要么内存溢出，要么数据丢失。所以，大容量数据必须使用流式处理。

#### 定义

Stream（流）是 Node.js 中处理流式数据的抽象接口，它的基本特征：

* 作为抽像接口，一般不直接使用，需要通过实现内部的抽象方法（例如 \_read、\_write、\_transform）来定义数据的格式，以及数据如何产生、如何消耗
* 作为 EventEmitter 子类，Stream 的内部数据传递依然是通过事件（data）来实现

任意一个流都是由一个可写端和一个可读端以及流内部的逻辑组成的

* 可读端：可以从流的可读端分步地拿到数据
* 可写端：可以通过可写端分步地往流内部写数据
* 内部逻辑：处理可写端写入的数据和负责往可读端输出数据

![img](./images/9614.png)

有两个流，一个可读一个可写，把可读流的可读端输出后再输入到可写流的可写端，就形成了最基本的**管道**（pipeline）。同时，可读流的可读端数据写到可写流的可写端的操作叫做 **pipe**。

![img](./images/9615.png)

管道也可以由多个流串联而成

![img](./images/9616.png)

这样的模型很容易让我们联想到中间件设计模式：

- 每个流负责一件独立的工作
- 每个流的输入和输出都符合约定的接口规范
- 每次这个 pipeline 的可写端写入数据，可读端便可获取到这份数据在整个 pipeline 中处理后的结果

#### 分类

在 Node.js 中，基于流的三个组成部分，对应产生了以下类型的流：

##### Readable

Readable 流也称只读流， 使用 Readable 类可以实现自定义可读流

* 自定义 `_read` 方法来实现流的读取过程
* 调用 `push` 方法来实际触发一次流数据读取，触发 data 事件
* 使用 `push(null)` 来表示流读取完毕，触发 finish 事件

```
const { Readable } = require('stream');

class StringReader extends Readable {
    constructor(str) {
        super();
        this._content = str;
    }

    _read() {
        for (let i = 0; i < this._content.length; i++) {
            this.push(this._content[i]);
        }

        this.push(null);
    }
}

const sr = new StringReader('qwert');

sr.on('data', (data) => {
    console.log('read:', data.toString());
});

sr.on('end', () => {
    console.log('end');
});

// 执行结果
read: q
read: w
read: e
read: r
read: t
end
```

##### Writable

通过继承 Writable 类可以实现自定义可写流。

* 自定义 `_write(data, enc, next)` 方法来实现流的写过程，在 `_write` 函数中必须调用 `next` 函数来通知流写入下一个数据
* 调用 `end` 方法来结束流的写入，此时也可以传入 data 参数，表示最后一次传入可写流的数据。调用 `end` 会触发可写流的 finish 事件。

```
const { Writable } = require('stream');

class StringWriter extends Writable {
    constructor() {
        super();
        this.content = '';
    }

    _write(data, enc, next) {
        if (data) {
            console.log('write:', data.toString());
            this.content += data.toString();
        }

        next();
    }
}

const sr = new StringWriter();

sr.on('finish', () => {
    console.log('finish:', sr.content);
});

sr.write('q');
sr.write('w');
sr.write('e');
sr.write('r');
sr.end('t');

// 执行结果
write: q
write: w
write: e
write: r
write: t
finish: qwert
```

##### Duplex

> /ˈduːpleks/ n. [通信]双工 adj. 双重的；复式的

Duplex 继承了 Readable 和 Writable 的所有特性，因此既可写也可读。

```
const { Duplex } = require('stream');

class MyDuplex extends Duplex {
    constructor(str) {
        super();
        this.readContent = str;
        this.writeContent = '';
    }

    _read() {
        for (let i = 0; i < this.readContent.length; i++) {
            this.push(this.readContent[i]);
        }

        this.push(null);
    }

    _write(data, enc, next) {
        if (data) {
            console.log('write:', data.toString());
            this.writeContent += data.toString();
        }

        next();
    }
}

const md = new MyDuplex('qwert');

md.on('data', (data) => {
    console.log('read:', data.toString());
});

md.on('end', () => {
    console.log('end');
});

md.on('finish', () => {
    console.log('finish:', md.writeContent);
});

md.write('q');
md.write('w');
md.write('e');
md.write('r');
md.end('t');

// 执行结果
write: q					// 同步执行
write: w
write: e
write: r
write: t
read: q						// 异步队列
read: w
read: e
read: r
read: t
finish: qwert
end
```

##### Transform 

Transform 又继承于 Duplex 的，**Duplex 流的可读端和可写端是相互独立的，但 Transform 流会自动把可写端写入的内容经过一些处理输出到可读端**。定义一个 Transform 流的步骤：

- 自定义 `_transform(buf, enc, next)` 方法来定义可读端输入结果的处理过程
- 在 `_transform` 方法中调用 `push` 方法来将处理结果输出到可读端
- 在 `_transform` 方法中调用 `next` 进行下一个处理。

```
const { Transform } = require('stream');

class MyTransform extends Transform {
    constructor() {
        super();
        this.content = '';
    }

    _transform(data, enc, next) {
        if (data) {
            console.log('write:', data.toString());
            const res = data.toString().toUpperCase();
            this.push(res);
            this.content += res;
        }
        next();
    }
}

const mt = new MyTransform();

mt.on('data', (data) => {
    console.log('read:', data.toString());
});

mt.on('end', () => {
    console.log('read end.');
});

mt.on('finish', () => {
    console.log('write finish.', mt.content);
});

mt.write('q');
mt.write('w');
mt.write('e');
mt.write('r');
mt.end('t');

// 执行结果
write: q
read: Q
write: w
read: W
write: e
read: E
write: r
read: R
write: t
read: T
write finish. QWERT
read end.
```

#### 应用

##### gulp

gulp 的核心设计模式即是基于流的中间件设计模式。

gulp 的使用方法：

```
const gulp = require('./gulp');									// gulp
const toUpperCase = require('./toUpperCase');		// 插件

gulp.src(['./a.txt', './b.txt'])
    .pipe(toUpperCase)
    .dest('./dest');
```

`gulp.src()` 和 `pipe()` 返回的都是可读可写流，可以接受输入并输出数据， 并具有 `pipe()` 和 `dest()` 方法。可以将这个返回的可读可写流抽象出来，实现如下：

```
// File.js
const fs = require('fs');
const path = require('path');
const { Transform } = require('stream');

class File extends Transform {
    constructor(props) {
        super({
            objectMode: true,
            ...props
        });
    }

    _transform(data, enc, next) {
        if (data) {
            // 流把自己处理的结果输出到可读端
            this.push(this.handler(data));
        }

        next();
    }

    // 流的处理过程，默认不做任何处理
    handler(a) { return a; }

    dest(dir) {
        // 若使用 dest 接口，则把流的处理结果写到目标文件夹中
        this.on('data', ({ filePath, content }) => {
            fs.writeFileSync(path.join(dir, filePath), content);
        });
    }
}

module.exports = File;
```

然后，基于该 File 对象实现 gulp 和插件 toUpperCase

```
// gulp.js
const fs = require('fs');
const File = require('./File');
const path = require('filePath');

module.exports = {
    src(filePaths) {
        // 创建一个流
        const stream = new File();

        for (let i = 0; i < filePaths.length; i++) {
            const filePath = filePaths[i];

            // 把文件的内容写入到流的可写端
            stream.write({
                filePath,
                content: fs.readFileSync(path.join(__dirname, filePath)).toString()
            });
        }

        return stream;
    }
};
```

```
// toUpperCase.js
const File = require('../File');
const toUpperCase = new File();

toUpperCase.handler = function (data) {
    if (data) {
        const { path, content } = data;

        return {
            path,
            content: content.toUpperCase()
        };
    }
};

module.exports = toUpperCase;
```

#### 参考

* https://juejin.im/entry/5b73da0fe51d4566390ccd23


